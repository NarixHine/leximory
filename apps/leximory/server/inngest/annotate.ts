import { inngest } from './client'
import { prefixUrl } from '@repo/env/config'
import { getLanguageStrategy } from '@/lib/languages'
import { getLibIdAndLangOfText, setTextAnnotationProgress, updateText } from '../db/text'
import { getSubsStatus } from '../db/subs'
import { articleAnnotationPrompt } from '../ai/annotate'
import { nanoAI } from '../ai/configs'
import { generateText } from 'ai'
import { revalidateTag } from 'next/cache'

const topicsPrompt = (input: string) => ({
    system: `
    ç”¨1~3ä¸ªä¸­æ–‡æ ‡ç­¾è¡¨ç¤ºä¸‹æ–‡çš„è¯é¢˜æˆ–å…³é”®è¯ã€‚æ¯ä¸ªå…³é”®è¯é—´ç”¨||åˆ†éš”ã€‚
    `,
    prompt: `è¯·ä»ä¸‹æ–‡æå–å‡º1~3ä¸ªä¸­æ–‡æ ‡ç­¾è¡¨ç¤ºä¸‹æ–‡çš„è¯é¢˜æˆ–å…³é”®è¯ï¼š
    
    ${input}`,
    maxOutputTokens: 100,
    ...nanoAI
})

const emojiPrompt = (input: string) => ({
    system: `ä½ æ˜¯ä¸€ä¸ªemojié€‰æ‹©å™¨ã€‚æ ¹æ®æ–‡ç« çš„ä¸»é¢˜å’Œæ°›å›´ï¼Œé€‰æ‹©ä¸€ä¸ªæœ€èƒ½ä»£è¡¨è¿™ç¯‡æ–‡ç« çš„emojiä¸”æ–°é¢–ä¸è½ä¿—å¥—ã€‚åªè¾“å‡ºä¸€ä¸ªemojiï¼Œä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–å†…å®¹ã€‚ç¦æ­¢é€‰å–å¯èƒ½å¼•èµ·å¼ºçƒˆè§†è§‰ä¸é€‚çš„emojiï¼Œå³ç¦æ­¢é€‰å–ä»»ä½•æ˜†è™«emojiã€‚`,
    prompt: `ä¸ºä»¥ä¸‹æ–‡ç« é€‰æ‹©ä¸€ä¸ªæœ‰è¡¨ç°åŠ›çš„emojiï¼š\n\n${input.slice(0, 500)}`,
    maxOutputTokens: 20,
    ...nanoAI
})

const chunkText = (text: string, maxLength: number): string[] => {
    // Handle edge cases
    if (!text) return []
    if (text.length <= maxLength) return [text]

    const chunks: string[] = []

    // Split by paragraphs (double newline)
    const paragraphs = text.split(/\n\s*\n/).filter(p => p.trim())
    let currentChunk = ''

    for (const paragraph of paragraphs) {
        // Case 1: Single paragraph longer than maxLength
        if (paragraph.length >= maxLength) {
            // Push existing chunk if any
            if (currentChunk) {
                chunks.push(currentChunk.trim())
                currentChunk = ''
            }

            // Split long paragraph by sentences when possible
            const sentences = paragraph.match(/[^.!?]+[.!?]+/g) || [paragraph]

            let sentenceChunk = ''
            for (const sentence of sentences) {
                if (sentence.length >= maxLength) {
                    // If single sentence is too long, split by maxLength
                    if (sentenceChunk) {
                        chunks.push(sentenceChunk.trim())
                        sentenceChunk = ''
                    }
                    for (let i = 0; i < sentence.length; i += maxLength) {
                        chunks.push(sentence.slice(i, Math.min(i + maxLength, sentence.length)).trim())
                    }
                } else if ((sentenceChunk + sentence).length >= maxLength) {
                    chunks.push(sentenceChunk.trim())
                    sentenceChunk = sentence
                } else {
                    sentenceChunk += sentence
                }
            }
            if (sentenceChunk) chunks.push(sentenceChunk.trim())
            continue
        }

        // Case 2: Normal paragraph handling
        if ((currentChunk + paragraph).length >= maxLength) {
            chunks.push(currentChunk.trim())
            currentChunk = paragraph + '\n\n'
        } else {
            currentChunk += paragraph + '\n\n'
        }
    }

    // Push final chunk if exists
    if (currentChunk) {
        chunks.push(currentChunk.trim())
    }

    return chunks.filter(chunk => chunk)
}

export const annotateFullArticle = inngest.createFunction(
    { id: 'annotate-article' },
    { event: 'app/article.imported' },
    async ({ step, event }) => {
        const { data: { article, textId, onlyComments, userId } } = event

        await step.run('set-annotation-progress-annotating', async () => {
            await setTextAnnotationProgress({ id: textId, progress: 'annotating' })
        })

        const { libId, lang } = await step.run('get-lib-id', async () => {
            return await getLibIdAndLangOfText({ id: textId })
        })

        const chunks = await step.run('chunk-text', async () => {
            return chunkText(article, getLanguageStrategy(lang).maxChunkSize)
        })

        const { topicsConfig, emojiConfig, annotationConfigs } = await step.run('get-annotate-configs', async () => {
            const topicsConfig = topicsPrompt(article)
            const emojiConfig = emojiPrompt(article)
            const annotationConfigs = await Promise.all(chunks.map(chunk => articleAnnotationPrompt(lang, chunk, onlyComments, userId)))
            return { topicsConfig, emojiConfig, annotationConfigs }
        })

        const [topics, emoji, ...annotatedChunks] = await Promise.all([
            step.ai.wrap('annotate-topics', generateText, topicsConfig),
            step.ai.wrap('generate-emoji', generateText, emojiConfig),
            ...annotationConfigs.map(async (config, index) => step.ai.wrap(`annotate-article-${index}`, generateText, config))
        ])

        const content = annotatedChunks.map(chunk => chunk.steps[0].content[0].type === 'text' ? chunk.steps[0].content[0].text : '').join('\n\n')

        const textUrl = `/library/${libId}/${textId}`

        await step.run('set-annotation-progress-saving', async () => {
            await setTextAnnotationProgress({ id: textId, progress: 'saving' })
        })
        await step.run('save-article', async () => {
            const generatedEmoji = emoji.steps[0].content[0].type === 'text' ? emoji.steps[0].content[0].text.trim() : undefined
            await updateText({
                id: textId,
                content,
                topics: topics.steps[0].content[0].type === 'text' ? topics.steps[0].content[0].text.split('||') : [],
                emoji: generatedEmoji
            })
            revalidateTag(`texts:${libId}`, 'max')
        })

        await step.run('set-annotation-progress-completed', async () => {
            await setTextAnnotationProgress({ id: textId, progress: 'completed' })
        })
        const { hasSubs, subscription } = await step.run('get-user-subs', async () => {
            return await getSubsStatus({ userId })
        })

        if (hasSubs && subscription) {
            await step.sendEvent('notify-user-on-article-imported', {
                name: 'app/notify',
                data: {
                    title: 'Leximory',
                    body: 'ğŸ˜ å¯¼å…¥æ–‡ç« æ³¨è§£å®Œæ¯•å•¦ï¼',
                    url: prefixUrl(textUrl),
                    subscription
                },
                user: { uid: userId }
            })
        }
    }
)
